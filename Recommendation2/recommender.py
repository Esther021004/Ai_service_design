import pandas as pd
import numpy as np
import ast
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize

# ===== í¬ë¡¤ë§ =====
def get_webdriver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

def crawl_schedule(url):
    try:
        driver = get_webdriver()
        driver.get(url)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "tablebody")))
        tablebody = driver.find_element(By.CLASS_NAME, "tablebody")
        subjects = tablebody.find_elements(By.CLASS_NAME, "subject")

        course_set = set()
        for subject in subjects:
            try:
                lecture = subject.find_element(By.TAG_NAME, "h3").text.strip()
                professor = subject.find_element(By.TAG_NAME, "em").text.strip()
                course_set.add({"ê³¼ëª©ëª…": lecture, "êµìˆ˜ëª…": professor})
            except:
                continue
        return [{"ê³¼ëª©ëª…": lec, "êµìˆ˜ëª…": prof} for lec, prof in sorted(course_set)]
    except Exception:
        return []

# ========== ìº í¼ìŠ¤ ì¸ì½”ë”© í•¨ìˆ˜ ==========
def encode_campus(campus):
    if campus == 'ìˆ˜ì •': return [1.0, 0.0]
    elif campus == 'ìš´ì •': return [0.0, 1.0]
    return [0.0, 0.0]  # ìƒê´€ì—†ìŒ
  
# ===== ì‚¬ìš©ì ë²¡í„°í™” =====
def vectorize_user_input(user):
    class_types = ['ë¸”ë Œë””ë“œ', 'ì›ê²©', 'ì¼ë°˜']
    attendance_types = ['ì „ìì¶œê²°', 'ì§ì ‘í˜¸ëª…', 'ëª¨ë¦„', 'ë³µí•©ì ', 'ë°˜ì˜ì•ˆí•¨']
    grade_types = ['ë„ˆê·¸ëŸ¬ì›€', 'ë³´í†µ', 'ëª¨ë¦„', 'ê¹ê¹í•¨']
    campus_types = ['ìˆ˜ì •', 'ìš´ì •']

    def convert_exam_count_scaled(value):
        if 'ì—†' in value: return 0.2
        if 'í•œ' in value: return 0.4
        if 'ë‘' in value: return 0.6
        if 'ì„¸' in value: return 0.8
        if 'ë„¤' in value or '4' in value: return 1.0
        return 0.4

    def scale_task_or_team(value):
        if 'ë§' in value: return 1.0
        if 'ì—†' in value: return 0.0
        return 0.5

    def rating_bucket(score):
        try: score = float(score)
        except: return 0.0
        if score <= 1: return 0.1
        elif score <= 2: return 0.2
        elif score <= 3: return 0.3
        elif score <= 4: return 0.4
        else: return 0.5

    campus_vec = [1 if user['ìº í¼ìŠ¤'] == t else 0 for t in campus_types] if user['ìº í¼ìŠ¤'] in campus_types else [0, 0]
    class_type_vec = [3 * (1 if user['ìˆ˜ì—…ìœ í˜•'] == t else 0) for t in class_types]
    attendance_vec = [1 if user['ì¶œê²°'] == t else 0 for t in attendance_types]
    ì„±ì _vec = [1 if user['ì„±ì '] == g else 0 for g in grade_types]
    ì‹œí—˜ = convert_exam_count_scaled(user['ì‹œí—˜']) / 3
    ê³¼ì œ = scale_task_or_team(user['ê³¼ì œ'])
    ì¡°ëª¨ì„ = scale_task_or_team(user['ì¡°ëª¨ì„'])
    ê°•ì˜ì‹œê°„ = 1.0 if user['ê°•ì˜ ì‹œê°„'] == 'í’€ê°•' else 0.0
    ê°•ì˜ë ¥ = {'ì¢‹ìŒ': 1.0, 'ë³´í†µ': 0.5, 'ë‚˜ì¨': 0.0}.get(user['ê°•ì˜ë ¥'], 0.5)
    í‰ì  = (rating_bucket(user['í‰ì ']) / 2) * 2

    return np.array([ì‹œí—˜, ê³¼ì œ, ì¡°ëª¨ì„] + attendance_vec + ì„±ì _vec + [ê°•ì˜ì‹œê°„, ê°•ì˜ë ¥] + class_type_vec + campus_vec + [í‰ì ])

# ===== ê¸°ì—¬ë„ í•´ì„ =====
def feature_map(index, value):
    if index == 0:
        if value == 0.2: return 'ì‹œí—˜ ì—†ìŒ'
        elif value == 0.4: return 'ì‹œí—˜ 1ë²ˆ'
        elif value == 0.6: return 'ì‹œí—˜ 2ë²ˆ'
        elif value == 0.8: return 'ì‹œí—˜ 3ë²ˆ'
        else: return 'ì‹œí—˜ 4ë²ˆ ì´ìƒ'
    elif index == 1:
        return 'ê³¼ì œ ë§ìŒ' if value == 1 else 'ê³¼ì œ ì—†ìŒ' if value == 0 else 'ê³¼ì œ ë³´í†µ/ëª¨ë¦„'
    elif index == 2:
        return 'ì¡°ëª¨ì„ ë§ìŒ' if value == 1 else 'ì¡°ëª¨ì„ ì—†ìŒ' if value == 0 else 'ì¡°ëª¨ì„ ë³´í†µ/ëª¨ë¦„'
    elif 3 <= index <= 7:
        return ['ì „ìì¶œê²°', 'ì§ì ‘í˜¸ëª…', 'ëª¨ë¦„', 'ë³µí•©ì ', 'ë°˜ì˜ì•ˆí•¨'][index - 3] if value == 1 else None
    elif 8 <= index <= 11:
        return ['ë„ˆê·¸ëŸ¬ì›€', 'ë³´í†µ', 'ëª¨ë¦„', 'ê¹ê¹í•¨'][index - 8] if value == 1 else None
    elif index == 12:
        return 'í’€ê°•' if value == 1 else 'í’€ê°•X' if value == 0 else 'ëª¨ë¦„'
    elif index == 13:
        return 'ê°•ì˜ë ¥ ì¢‹ìŒ' if value == 1 else 'ê°•ì˜ë ¥ ë‚˜ì¨' if value == 0 else 'ê°•ì˜ë ¥ ë³´í†µ/ëª¨ë¦„'
    elif 14 <= index <= 16:
        value = value / 3
        return ['ë¸”ë Œë””ë“œ', 'ì›ê²©', 'ì¼ë°˜'][index - 14] if value == 1 else None
    elif 17 <= index <= 18:
        return ['ìˆ˜ì •ìº í¼ìŠ¤', 'ìš´ì •ìº í¼ìŠ¤'][index - 17] if value == 1 else None
    elif index == 19:
        value = value / 2
        if value <= 0.2: return 'í‰ì  â‰¤ 2'
        elif value <= 0.3: return 'í‰ì  â‰¤ 3'
        elif value <= 0.4: return 'í‰ì  â‰¤ 4'
        else: return 'í‰ì  â‰¤ 5'
    return None

def get_top_3_features(user_vec, lecture_vec):
    contributions = user_vec * lecture_vec
    top_indices = np.argsort(contributions)[::-1]
    reasons = []
    for i in top_indices:
        reason = feature_map(i, lecture_vec[i])
        if reason and reason not in reasons:
            reasons.append(reason)
        if len(reasons) == 3:
            break
    return reasons

# ===== í•„ìˆ˜ì¶”ì²œ ë¶ˆëŸ¬ì˜¤ê¸° =====
def load_required_courses(user_major, user_college=None, user_grade=None):
    if user_grade != 1 or user_college == "ì°½ì˜ìœµí•©í•™ë¶€":
        return pd.DataFrame(columns=['ê³¼ëª©ëª…', 'êµìˆ˜ëª…', 'ì´ìˆ˜êµ¬ë¶„', 'ì˜ì—­', 'ì¶”ì²œì´ìœ '])

    group1 = ['ì˜ì–´ì˜ë¬¸í•™ê³¼','ì¼ë³¸ì–´ë¬¸Â·ë¬¸í™”í•™ê³¼','ë…ì¼ì–´ë¬¸Â·ë¬¸í™”í•™ê³¼','í”„ë‘ìŠ¤ì–´ë¬¸Â·ë¬¸í™”í•™ê³¼','ì¤‘êµ­ì–´ë¬¸Â·ë¬¸í™”í•™ê³¼','ë²•í•™ê³¼','êµ­ì–´êµ­ë¬¸í•™ê³¼','ì‚¬í•™ê³¼']
    group2 = ['ì •ì¹˜ì™¸êµí•™ê³¼','ì§€ë¦¬í•™ê³¼','ê²½ì˜í•™ê³¼','ë¯¸ë””ì–´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜í•™ê³¼','ì‹¬ë¦¬í•™ê³¼','ë™ì–‘í™”ê³¼','ì„œì–‘í™”ê³¼','ì¡°ì†Œê³¼','ì„±ì•…ê³¼','ê¸°ì•…ê³¼','ì‘ê³¡ê³¼','ìŠ¤í¬ì¸ ê³¼í•™í•™ë¶€','ê³µì˜ˆê³¼','ë””ìì¸ê³¼','ê²½ì œí•™ê³¼']
    group3 = ['ì‚¬íšŒë³µì§€í•™ê³¼','ì˜ë¥˜ì‚°ì—…í•™ê³¼','ì†Œë¹„ìì‚°ì—…í•™ê³¼','ë¬¸í™”ì˜ˆìˆ ê²½ì˜í•™ê³¼','í˜„ëŒ€ì‹¤ìš©ìŒì•…í•™ê³¼','ë¬´ìš©ì˜ˆìˆ í•™ê³¼','ê°„í˜¸í•™ê³¼','ë·°í‹°ì‚°ì—…í•™ê³¼','ë¯¸ë””ì–´ì˜ìƒì—°ê¸°í•™ê³¼']


    file = None
    if user_major in group1:
        file = 'í•„ìˆ˜ì¶”ì²œ_1.csv'
    elif user_major in group2:
        file = 'í•„ìˆ˜ì¶”ì²œ_2.csv'
    elif user_major in group3:
        file = 'í•„ìˆ˜ì¶”ì²œ_3.csv'
    else:
        file = f'í•„ìˆ˜ì¶”ì²œ_{user_major}.csv'

    try:
        df = pd.read_csv(file, encoding='utf-8-sig')

        # ê·¸ë£¹3ì´ë©´ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° í¬í•¨
        if user_major in group3:
            df = df[(df.get('ì „ê³µëª…', user_major) == user_major) | (df['ê³¼ëª©ëª…'] == 'íŒŒì´ì¬í”„ë¡œê·¸ë˜ë°')]
        # ê·¸ë£¹1, ê·¸ë£¹2ëŠ” ì „ê³µëª… ê¸°ì¤€ í•„í„°ë§
        elif user_major in group1 + group2:
            df = df[df['ì „ê³µëª…'] == user_major]
        # ê¸°íƒ€ ì „ê³µì€ ì „ê³µëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ í•„í„° ì—†ì´ ì „ì²´ ì‚¬ìš©
        else:
            pass  # í•„í„°ë§ ì•ˆ í•¨

        # ì¶œë ¥ ì»¬ëŸ¼ ì •ë¦¬
        if 'ì¶”ì²œì´ìœ ' not in df.columns:
            df['ì¶”ì²œì´ìœ '] = 'ì „ê³µ í•„ìˆ˜ ì¶”ì²œ'
        return df[['ê³¼ëª©ëª…','êµìˆ˜ëª…','ì´ìˆ˜êµ¬ë¶„','ì˜ì—­','ì¶”ì²œì´ìœ ']].reset_index(drop=True)
    except:
        return pd.DataFrame(columns=['ê³¼ëª©ëª…','êµìˆ˜ëª…','ì´ìˆ˜êµ¬ë¶„','ì˜ì—­','ì¶”ì²œì´ìœ '])

# ===== êµì–‘ ì¶”ì²œ =====
def recommend_liberal(user_vec, prev_lectures, í•„ìˆ˜ê³¼ëª©ëª…, user_grade):
    df = pd.read_csv("ê°•ì˜_ë²¡í„°í™”_ì¼ë°˜êµì–‘.csv", encoding='utf-8-sig')
    df['parsed_vector'] = df['ì „ì²´ ë²¡í„°'].apply(ast.literal_eval)

    # ğŸ”¹ 1í•™ë…„ì´ ì•„ë‹ˆë©´ ê³µí†µêµì–‘ ì œì™¸
    if user_grade != 1:
        df['ì´ìˆ˜êµ¬ë¶„'] = df['ì´ìˆ˜êµ¬ë¶„'].astype(str).str.strip().str.replace(r"\s+", "", regex=True)
        df = df[df['ì´ìˆ˜êµ¬ë¶„'] != 'ê³µí†µêµì–‘']
      
    lecture_matrix = np.array(df['parsed_vector'].tolist())[:, :20]
    sim = cosine_similarity(normalize(user_vec.reshape(1, -1)), normalize(lecture_matrix))[0]
    df['ìœ ì‚¬ë„'] = sim

    # ì´ì „ ìˆ˜ê°•í•œ ê³¼ëª©ëª… + í•„ìˆ˜ì¶”ì²œ ê³¼ëª©ëª… ì œì™¸
    prev_titles = set(x['ê³¼ëª©ëª…'].strip().lower() for x in prev_lectures)
    í•„ìˆ˜ê³¼ëª©ëª… = set(c.strip().lower() for c in í•„ìˆ˜ê³¼ëª©ëª…)
    ì œì™¸ê³¼ëª©ëª… = prev_titles.union(í•„ìˆ˜ê³¼ëª©ëª…)
  
    df = df[~df['ê³¼ëª©ëª…'].str.strip().str.lower().isin(ì œì™¸ê³¼ëª©ëª…)]
    df = df.drop_duplicates(subset=['ê³¼ëª©ëª…','êµìˆ˜ëª…'])

    top_df = df.sort_values(by='ìœ ì‚¬ë„', ascending=False).head(30)
    
    results = []
    for _, row in top_df.iterrows():
        lecture_vec = np.array(row['parsed_vector'])[:20]
        reasons = get_top_3_features(user_vec.flatten(), lecture_vec)
        results.append({
            'ê³¼ëª©ëª…': row['ê³¼ëª©ëª…'],
            'êµìˆ˜ëª…': row['êµìˆ˜ëª…'],
            'ì´ìˆ˜êµ¬ë¶„': row['ì´ìˆ˜êµ¬ë¶„'],
            'ì˜ì—­': row['ì˜ì—­'],
            'ì¶”ì²œì´ìœ ': reasons
        })
    return results

# ===== í†µí•© êµì–‘ ì¶”ì²œ =====
def recommend_combined(user_input, user_vec, prev_lectures):
    í•„ìˆ˜ì¶”ì²œ = load_required_courses(
        user_major=user_input['ì „ê³µ'],
        user_college=user_input['ë‹¨ê³¼ëŒ€í•™'],
        user_grade=user_input['í•™ë…„']
    )
  
    í•„ìˆ˜ì¶”ì²œ_dict = í•„ìˆ˜ì¶”ì²œ.to_dict('records')

    # í•„ìˆ˜ ì¶”ì²œ ê³¼ëª©ëª… ëª©ë¡ (ì†Œë¬¸ì + ê³µë°±ì œê±°ë¡œ í†µì¼)
    í•„ìˆ˜ê³¼ëª©ëª… = set(c.strip().lower() for c in í•„ìˆ˜ì¶”ì²œ['ê³¼ëª©ëª…'].tolist())

    # ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ
    ìœ ì‚¬ë„ì¶”ì²œ = recommend_liberal(user_vec, prev_lectures, í•„ìˆ˜ê³¼ëª©ëª…, user_input['í•™ë…„'])
  
    # ìœ ì‚¬ë„ ì¶”ì²œ ì¤‘ í•„ìˆ˜ì¶”ì²œê³¼ ê³¼ëª©ëª… ê²¹ì¹˜ëŠ” í•­ëª© ì œê±°
    ìœ ì‚¬ë„ì¶”ì²œ_filtered = [
        r for r in ìœ ì‚¬ë„ì¶”ì²œ
        if r['ê³¼ëª©ëª…'].strip().lower() not in í•„ìˆ˜ê³¼ëª©ëª…
    ]
    
    # ìµœì¢… ì¶”ì²œ 15ê°œë¡œ ì œí•œ
    needed = 15 - len(í•„ìˆ˜ì¶”ì²œ_dict)
    final_recommend = í•„ìˆ˜ì¶”ì²œ_dict + ìœ ì‚¬ë„ì¶”ì²œ_filtered[:needed]
    return final_recommend

# ===== ì§„ë¡œì†Œì–‘ ì¶”ì²œ =====
def recommend_career(user_input, user_vec, prev_lectures):
    df = pd.read_csv("ê°•ì˜_ë²¡í„°í™”_ì§„ë¡œì†Œì–‘.csv", encoding='utf-8-sig')
    df['parsed_vector'] = df['ì „ì²´ ë²¡í„°'].apply(ast.literal_eval)
  
    lecture_matrix = np.array(df['parsed_vector'].tolist())[:, :20]
    sim = cosine_similarity(normalize(user_vec.reshape(1, -1)), normalize(lecture_matrix))[0]
    df['ìœ ì‚¬ë„'] = sim

    # ğŸ”¹ ì´ì „ ìˆ˜ê°•í•œ ê³¼ëª©ëª… (ì†Œë¬¸ì + ê³µë°± ì œê±°)
    prev_titles = set(x['ê³¼ëª©ëª…'].strip().lower() for x in prev_lectures)
    
    # ğŸ”¹ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì œì™¸ ê³¼ëª© ì„¸íŠ¸
    ì œì™¸ê³¼ëª©ëª… = set(prev_titles)
    must_recommend = []

    # âœ… ì¡°ê±´ ì¶©ì¡± ì‹œ 'ì „ê³µë³„ì§„ë¡œíƒìƒ‰' ë¬´ì¡°ê±´ ì¶”ì²œ
    if user_input['í•™ë…„'] == 1 and user_input['ì „ê³µ'] not in ['ì²­ì •ì‹ ì†Œì¬ê³µí•™ê³¼', 'ë°”ì´ì˜¤ì‹í’ˆê³µí•™ê³¼', 'ë·°í‹°ì‚°ì—…í•™ê³¼'] and user_input['ë‹¨ê³¼ëŒ€í•™'] != 'ì‚¬ë²”ëŒ€í•™':
        íƒìƒ‰_row = df[df['ê³¼ëª©ëª…'].str.contains("ì „ê³µë³„ ì§„ë¡œ íƒìƒ‰", case=False)]
        for _, row in íƒìƒ‰_row.iterrows():
            title = row['ê³¼ëª©ëª…'].strip().lower()
            if title not in ì œì™¸ê³¼ëª©ëª…:
                lecture_vec = np.array(row['parsed_vector'])[:20]
                reasons = get_top_3_features(user_vec.flatten(), lecture_vec)
                must_recommend.append({
                    'ê³¼ëª©ëª…': row['ê³¼ëª©ëª…'],
                    'êµìˆ˜ëª…': row['êµìˆ˜ëª…'],
                    'ì´ìˆ˜êµ¬ë¶„': row['ì´ìˆ˜êµ¬ë¶„'],
                    'ì˜ì—­': row['ì˜ì—­'],
                    'ì¶”ì²œì´ìœ ': reasons
                })
                ì œì™¸ê³¼ëª©ëª….add(title)
                break

    # âœ… ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ (ì¤‘ë³µ ë°©ì§€)
    df = df.sort_values(by='ìœ ì‚¬ë„', ascending=False)
    results = []
    for _, row in df.iterrows():
        title = row['ê³¼ëª©ëª…'].strip().lower()
        if title in ì œì™¸ê³¼ëª©ëª…:
            continue
        lecture_vec = np.array(row['parsed_vector'])[:20]
        reasons = get_top_3_features(user_vec.flatten(), lecture_vec)
        results.append({
            'ê³¼ëª©ëª…': row['ê³¼ëª©ëª…'],
            'êµìˆ˜ëª…': row['êµìˆ˜ëª…'],
            'ì´ìˆ˜êµ¬ë¶„': row['ì´ìˆ˜êµ¬ë¶„'],
            'ì˜ì—­': row['ì˜ì—­'],
            'ì¶”ì²œì´ìœ ': reasons
        })
        if len(results) >= (2 - len(must_recommend)):
            break

    return must_recommend + results
