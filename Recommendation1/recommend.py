import pandas as pd
import numpy as np
import ast
import re
import traceback
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize


def get_webdriver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)


def crawl_schedule(url):
    try:
        driver = get_webdriver()
        driver.get(url)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "tablebody")))
        tablebody = driver.find_element(By.CLASS_NAME, "tablebody")
        subjects = tablebody.find_elements(By.CLASS_NAME, "subject")

        course_set = set()
        for subject in subjects:
            try:
                lecture = subject.find_element(By.TAG_NAME, "h3").text.strip()
                professor = subject.find_element(By.TAG_NAME, "em").text.strip()
                course_set.add((lecture, professor))
            except:
                continue
        return [{"ê³¼ëª©ëª…": lec, "êµìˆ˜ëª…": prof} for lec, prof in sorted(course_set)]
    except Exception:
        return []

def vectorize_user_input(user):
    class_types = ['ë¸”ë Œë””ë“œ', 'ì›ê²©', 'ì¼ë°˜']
    attendance_types = ['ì „ìì¶œê²°', 'ì§ì ‘í˜¸ëª…', 'ëª¨ë¦„', 'ë³µí•©ì ', 'ë°˜ì˜ì•ˆí•¨']
    grade_types = ['ë„ˆê·¸ëŸ¬ì›€', 'ë³´í†µ', 'ëª¨ë¦„', 'ê¹ê¹í•¨']

    def convert_exam_count_scaled(value):
        if 'ì—†' in value: return 0.2
        if 'í•œ' in value: return 0.4
        if 'ë‘' in value: return 0.6
        if 'ì„¸' in value: return 0.8
        if 'ë„¤' in value or '4' in value: return 1.0
        return 0.4

    def scale_task_or_team(value):
        if 'ë§' in value: return 1.0
        if 'ì—†' in value: return 0.0
        return 0.5

    def rating_bucket(score):
        try: score = float(score)
        except: return 0.0
        if 4.0 <= score <= 5.0: return 0.5
        elif 3.0 <= score < 4.0: return 0.4
        elif 2.0 <= score < 3.0: return 0.3
        elif 1.0 <= score < 2.0: return 0.2
        return 0.0

    ìˆ˜ì—…ìœ í˜•_weighted = [1 if user['ìˆ˜ì—…ìœ í˜•'] == t else 0 for t in class_types]
    ì¶œê²° = [1 if user['ì¶œê²°'] == t else 0 for t in attendance_types]
    ì‹œí—˜ = convert_exam_count_scaled(user['ì‹œí—˜']) / 3
    ê³¼ì œ = scale_task_or_team(user['ê³¼ì œ'])
    ì¡°ëª¨ì„ = scale_task_or_team(user['ì¡°ëª¨ì„'])
    ì„±ì  = [1 if user['ì„±ì '] == g else 0 for g in grade_types]
    ê°•ì˜ì‹œê°„ = 1.0 if user['ê°•ì˜ ì‹œê°„'] == 'í’€ê°•' else 0.0
    ê°•ì˜ë ¥ = {'ì¢‹ìŒ': 1.0, 'ë³´í†µ': 0.5, 'ë‚˜ì¨': 0.0}.get(user['ê°•ì˜ë ¥'], 0.5)
    í‰ì _weighted = rating_bucket(user['í‰ì ']) / 2

    return np.array(ìˆ˜ì—…ìœ í˜•_weighted + ì¶œê²° + [ì‹œí—˜, ê³¼ì œ, ì¡°ëª¨ì„] + ì„±ì  + [ê°•ì˜ì‹œê°„, ê°•ì˜ë ¥, í‰ì _weighted])


def feature_map(index, value):
    if 0 <= index <= 2:
        value = value / 3
        return ['ë¸”ë Œë””ë“œ', 'ì›ê²©', 'ì¼ë°˜'][index] if value > 0 else None
    elif 3 <= index <= 7:
        return ['ì „ìì¶œê²°', 'ì§ì ‘í˜¸ëª…', 'ëª¨ë¦„', 'ë³µí•©ì ', 'ë°˜ì˜ì•ˆí•¨'][index - 3] if value == 1 else None
    elif index == 8:
        return ['ì‹œí—˜X', 'ì‹œí—˜1ë²ˆ', 'ì‹œí—˜2ë²ˆ', 'ì‹œí—˜3ë²ˆ', 'ì‹œí—˜4ë²ˆì´ìƒ'][int(value * 5 - 1)]
    elif index == 9:
        return 'ê³¼ì œë§ìŒ' if value == 1 else 'ê³¼ì œì—†ìŒ' if value == 0 else 'ê³¼ì œë³´í†µ/ëª¨ë¦„'
    elif index == 10:
        return 'ì¡°ëª¨ì„ë§ìŒ' if value == 1 else 'ì¡°ëª¨ì„ì—†ìŒ' if value == 0 else 'ì¡°ëª¨ì„ë³´í†µ/ëª¨ë¦„'
    elif 11 <= index <= 14:
        return ['ë„ˆê·¸ëŸ¬ì›€', 'ë³´í†µ', 'ëª¨ë¦„', 'ê¹ê¹í•¨'][index - 11] if value == 1 else None
    elif index == 15:
        return 'í’€ê°•' if value == 1 else 'í’€ê°•X'
    elif index == 16:
        return 'ê°•ì˜ë ¥ì¢‹ìŒ' if value == 1 else 'ê°•ì˜ë ¥ë‚˜ì¨' if value == 0 else 'ê°•ì˜ë ¥ë³´í†µ/ëª¨ë¦„'
    elif index == 17:
        value = value / 2
        if value <= 0.2: return 'í‰ì â‰¤2'
        elif value <= 0.3: return 'í‰ì â‰¤3'
        elif value <= 0.4: return 'í‰ì â‰¤4'
        else: return 'í‰ì â‰¤5'
    return None


def get_top_3_features(user_vec, lecture_vec):
    contributions = user_vec * lecture_vec
    top_indices = np.argsort(contributions)[::-1]
    reasons = []
    for i in top_indices:
        reason = feature_map(i, lecture_vec[i])
        if reason and reason not in reasons:
            reasons.append(reason)
        if len(reasons) == 3:
            break
    return reasons


# ==================== ì¶”ì²œ í•¨ìˆ˜ ====================
def recommend_major_lectures(user_input: dict, previous_courses: list) -> list:
    dept = user_input['ë‹¨ê³¼ëŒ€í•™']
    major = user_input['ì „ê³µ']
    sub = user_input['ì„¸ë¶€ì „ê³µ']
    filename = f"ê°•ì˜_ë²¡í„°í™”_{dept}_{major}_{sub}.csv" if sub else f"ê°•ì˜_ë²¡í„°í™”_{dept}_{major}.csv"
    df = pd.read_csv(filename, encoding='utf-8-sig')

    í•™ë…„_ì˜ì—­ = str(user_input['í•™ë…„']) + "ì˜ì—­"
    df = df[df['ì˜ì—­'].str.contains(í•™ë…„_ì˜ì—­)].copy()

    # ê³¼ëª©ëª… ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    prev_subjects = set([p['ê³¼ëª©ëª…'] for p in previous_courses])
    df = df[~df['ê³¼ëª©ëª…'].isin(prev_subjects)]

    df['parsed_vector'] = df['ì „ì²´ë²¡í„°'].apply(ast.literal_eval)
    lecture_matrix = np.array(df['parsed_vector'].tolist())[:, :18]

    user_vec = vectorize_user_input(user_input).reshape(1, -1)
    sim = cosine_similarity(normalize(user_vec), normalize(lecture_matrix))[0]
    df['ìœ ì‚¬ë„'] = sim

    top_df = df.sort_values(by='ìœ ì‚¬ë„', ascending=False).drop_duplicates(['ê³¼ëª©ëª…']).head(5)

    recommendations = []
    for _, row in top_df.iterrows():
        lecture_vec = np.array(row['parsed_vector'])[:18]
        reasons = get_top_3_features(user_vec.flatten(), lecture_vec)
        recommendations.append({
            'ê³¼ëª©ëª…': row['ê³¼ëª©ëª…'],
            'êµìˆ˜ëª…': row['êµìˆ˜ëª…'],
            'ê°œì„¤í•™ê³¼ì „ê³µ': row['ê°œì„¤í•™ê³¼ì „ê³µ'],
            'ì˜ì—­': row['ì˜ì—­'],
            'ì¶”ì²œ ì´ìœ ': reasons
        })

    return recommendations

# ==================== ì‹¤í–‰ ====================
if __name__ == "__main__":
    # âœ… ì—¬ëŸ¬ í•™ê¸° ë§í¬ ì…ë ¥ë°›ê¸°
    previous_courses = []
    semester_urls = {}

    print("ğŸ’¬ ìˆ˜ê°• í•™ê¸°ë³„ ì—ë¸Œë¦¬íƒ€ì„ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì…ë ¥ ì¢…ë£Œ: ì—†ìŒ)")
    while True:
        semester = input("ğŸ“Œ ìˆ˜ê°• í•™ê¸° ì…ë ¥ (ì˜ˆ: 24-1): ").strip()
        if semester.lower() == 'ì—†ìŒ':
            break
        url = input(f"ğŸ”— {semester}í•™ê¸° ì—ë¸Œë¦¬íƒ€ì„ ë§í¬: ").strip()
        courses = crawl_schedule(url)
        semester_urls[semester] = courses
        previous_courses.extend(courses)

    print("\nğŸ“š [ì´ì „ ìˆ˜ê°• ë‚´ì—­]")
    for sem, course_list in semester_urls.items():
        print(f"- {sem}: {course_list}")

    user_input = get_user_input()
    recommendations = recommend_major_lectures(user_input, previous_courses)

    print("\nâœ¨ [ì „ê³µ ê°•ì˜ ì¶”ì²œ ê²°ê³¼]")
    for r in recommendations:
        print(f"\nğŸ“˜ {r['ê³¼ëª©ëª…']} ({r['êµìˆ˜ëª…']})")
        print(f"ê°œì„¤í•™ê³¼ì „ê³µ: {r['ê°œì„¤í•™ê³¼ì „ê³µ']} | ì˜ì—­: {r['ì˜ì—­']}")
        print("ì¶”ì²œ ì´ìœ :", ", ".join(r['ì¶”ì²œ ì´ìœ ']))
